{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and preprocessing and miscellaneous functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use mnist_train.csv as our training data and mnist_test.csv as our validation set\n",
    "http://pjreddie.com/projects/mnist-in-csv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('mnist_train.csv',header=None)\n",
    "test_set = pd.read_csv('mnist_test.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   775  776  777  778  \\\n",
       "0    7    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "1    2    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "2    1    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "4    4    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "\n",
       "   779  780  781  782  783  784  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efc941eb250>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDkcJ4cR3OEoIJ77DUUI48R2OEuL/AytVNTNhmicLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efc955cffd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make sure the images are alright\n",
    "plt.imshow(trainX.reshape(len(trainX),28,28)[0],cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get labels in own array\n",
    "train_lb=np.array(train_set[0])\n",
    "test_lb=np.array(test_set[0])\n",
    "\n",
    "#one hot encode the labels\n",
    "train_lb=(np.arange(10) == train_lb[:,None]).astype(np.float32)\n",
    "test_lb=(np.arange(10) == test_lb[:,None]).astype(np.float32)\n",
    "\n",
    "#drop the labels column from training dataframe\n",
    "trainX=train_set.drop(0,axis=1)\n",
    "testX=test_set.drop(0,axis=1)\n",
    "\n",
    "#put in correct float32 array format\n",
    "trainX=np.array(trainX).astype(np.float32)\n",
    "testX=np.array(testX).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reformat the data so it's not flat\n",
    "trainX=trainX.reshape(len(trainX),28,28,1)\n",
    "testX = testX.reshape(len(testX),28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get a validation set and remove it from the train set\n",
    "trainX,valX,train_lb,val_lb=trainX[0:(len(trainX)-500),:,:,:],trainX[(len(trainX)-500):len(trainX),:,:,:],\\\n",
    "                            train_lb[0:(len(trainX)-500),:],train_lb[(len(trainX)-500):len(trainX),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#need to batch the test data because running low on memory\n",
    "class test_batchs:\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        self.batch_index = 0\n",
    "    def nextBatch(self,batch_size):\n",
    "        if (batch_size+self.batch_index) > self.data.shape[0]:\n",
    "            print \"batch sized is messed up\"\n",
    "        batch = self.data[self.batch_index:(self.batch_index+batch_size),:,:,:]\n",
    "        self.batch_index= self.batch_index+batch_size\n",
    "        return batch\n",
    "\n",
    "#set the test batchsize\n",
    "test_batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns accuracy of model\n",
    "def accuracy(target,predictions):\n",
    "    return(100.0*np.sum(np.argmax(target,1) == np.argmax(predictions,1))/target.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use os to get our current working directory so we can save variable\n",
    "file_path = os.getcwd()+'/model.ckpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Inception modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "map1 = 32\n",
    "map2 = 64\n",
    "num_fc1 = 700 #1028\n",
    "num_fc2 = 10\n",
    "reduce1x1 = 16\n",
    "dropout=0.5\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    #train data and labels\n",
    "    X = tf.placeholder(tf.float32,shape=(batch_size,28,28,1))\n",
    "    y_ = tf.placeholder(tf.float32,shape=(batch_size,10))\n",
    "    \n",
    "    #validation data\n",
    "    tf_valX = tf.placeholder(tf.float32,shape=(len(valX),28,28,1))\n",
    "    \n",
    "    #test data\n",
    "    tf_testX=tf.placeholder(tf.float32,shape=(test_batch_size,28,28,1))\n",
    "    \n",
    "    def createWeight(size,Name):\n",
    "        return tf.Variable(tf.truncated_normal(size, stddev=0.1),\n",
    "                          name=Name)\n",
    "    \n",
    "    def createBias(size,Name):\n",
    "        return tf.Variable(tf.constant(0.1,shape=size),\n",
    "                          name=Name)\n",
    "    \n",
    "    def conv2d_s1(x,W):\n",
    "        return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n",
    "    \n",
    "    def max_pool_3x3_s1(x):\n",
    "        return tf.nn.max_pool(x,ksize=[1,3,3,1],\n",
    "                             strides=[1,1,1,1],padding='SAME')\n",
    "    \n",
    "    \n",
    "    #Inception Module1\n",
    "    #\n",
    "    #follows input\n",
    "    W_conv1_1x1_1 = createWeight([1,1,1,map1],'W_conv1_1x1_1')\n",
    "    b_conv1_1x1_1 = createWeight([map1],'b_conv1_1x1_1')\n",
    "    \n",
    "    #follows input\n",
    "    W_conv1_1x1_2 = createWeight([1,1,1,reduce1x1],'W_conv1_1x1_2')\n",
    "    b_conv1_1x1_2 = createWeight([reduce1x1],'b_conv1_1x1_2')\n",
    "    \n",
    "    #follows input\n",
    "    W_conv1_1x1_3 = createWeight([1,1,1,reduce1x1],'W_conv1_1x1_3')\n",
    "    b_conv1_1x1_3 = createWeight([reduce1x1],'b_conv1_1x1_3')\n",
    "    \n",
    "    #follows 1x1_2\n",
    "    W_conv1_3x3 = createWeight([3,3,reduce1x1,map1],'W_conv1_3x3')\n",
    "    b_conv1_3x3 = createWeight([map1],'b_conv1_3x3')\n",
    "    \n",
    "    #follows 1x1_3\n",
    "    W_conv1_5x5 = createWeight([5,5,reduce1x1,map1],'W_conv1_5x5')\n",
    "    b_conv1_5x5 = createBias([map1],'b_conv1_5x5')\n",
    "    \n",
    "    #follows max pooling\n",
    "    W_conv1_1x1_4= createWeight([1,1,1,map1],'W_conv1_1x1_4')\n",
    "    b_conv1_1x1_4= createWeight([map1],'b_conv1_1x1_4')\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Inception Module2\n",
    "    #\n",
    "    #follows inception1\n",
    "    W_conv2_1x1_1 = createWeight([1,1,4*map1,map2],'W_conv2_1x1_1')\n",
    "    b_conv2_1x1_1 = createWeight([map2],'b_conv2_1x1_1')\n",
    "    \n",
    "    #follows inception1\n",
    "    W_conv2_1x1_2 = createWeight([1,1,4*map1,reduce1x1],'W_conv2_1x1_2')\n",
    "    b_conv2_1x1_2 = createWeight([reduce1x1],'b_conv2_1x1_2')\n",
    "    \n",
    "    #follows inception1\n",
    "    W_conv2_1x1_3 = createWeight([1,1,4*map1,reduce1x1],'W_conv2_1x1_3')\n",
    "    b_conv2_1x1_3 = createWeight([reduce1x1],'b_conv2_1x1_3')\n",
    "    \n",
    "    #follows 1x1_2\n",
    "    W_conv2_3x3 = createWeight([3,3,reduce1x1,map2],'W_conv2_3x3')\n",
    "    b_conv2_3x3 = createWeight([map2],'b_conv2_3x3')\n",
    "    \n",
    "    #follows 1x1_3\n",
    "    W_conv2_5x5 = createWeight([5,5,reduce1x1,map2],'W_conv2_5x5')\n",
    "    b_conv2_5x5 = createBias([map2],'b_conv2_5x5')\n",
    "    \n",
    "    #follows max pooling\n",
    "    W_conv2_1x1_4= createWeight([1,1,4*map1,map2],'W_conv2_1x1_4')\n",
    "    b_conv2_1x1_4= createWeight([map2],'b_conv2_1x1_4')\n",
    "    \n",
    "    \n",
    "\n",
    "    #Fully connected layers\n",
    "    #since padding is same, the feature map with there will be 4 28*28*map2\n",
    "    W_fc1 = createWeight([28*28*(4*map2),num_fc1],'W_fc1')\n",
    "    b_fc1 = createBias([num_fc1],'b_fc1')\n",
    "    \n",
    "    W_fc2 = createWeight([num_fc1,num_fc2],'W_fc2')\n",
    "    b_fc2 = createBias([num_fc2],'b_fc2')\n",
    "\n",
    "    def model(x,train=True):\n",
    "        #Inception Module 1\n",
    "        conv1_1x1_1 = conv2d_s1(x,W_conv1_1x1_1)+b_conv1_1x1_1\n",
    "        conv1_1x1_2 = tf.nn.relu(conv2d_s1(x,W_conv1_1x1_2)+b_conv1_1x1_2)\n",
    "        conv1_1x1_3 = tf.nn.relu(conv2d_s1(x,W_conv1_1x1_3)+b_conv1_1x1_3)\n",
    "        conv1_3x3 = conv2d_s1(conv1_1x1_2,W_conv1_3x3)+b_conv1_3x3\n",
    "        conv1_5x5 = conv2d_s1(conv1_1x1_3,W_conv1_5x5)+b_conv1_5x5\n",
    "        maxpool1 = max_pool_3x3_s1(x)\n",
    "        conv1_1x1_4 = conv2d_s1(maxpool1,W_conv1_1x1_4)+b_conv1_1x1_4\n",
    "        \n",
    "        #concatenate all the feature maps and hit them with a relu\n",
    "        inception1 = tf.nn.relu(tf.concat(3,[conv1_1x1_1,conv1_3x3,conv1_5x5,conv1_1x1_4]))\n",
    "\n",
    "        \n",
    "        #Inception Module 2\n",
    "        conv2_1x1_1 = conv2d_s1(inception1,W_conv2_1x1_1)+b_conv2_1x1_1\n",
    "        conv2_1x1_2 = tf.nn.relu(conv2d_s1(inception1,W_conv2_1x1_2)+b_conv2_1x1_2)\n",
    "        conv2_1x1_3 = tf.nn.relu(conv2d_s1(inception1,W_conv2_1x1_3)+b_conv2_1x1_3)\n",
    "        conv2_3x3 = conv2d_s1(conv2_1x1_2,W_conv2_3x3)+b_conv2_3x3\n",
    "        conv2_5x5 = conv2d_s1(conv2_1x1_3,W_conv2_5x5)+b_conv2_5x5\n",
    "        maxpool2 = max_pool_3x3_s1(inception1)\n",
    "        conv2_1x1_4 = conv2d_s1(maxpool2,W_conv2_1x1_4)+b_conv2_1x1_4\n",
    "        \n",
    "        #concatenate all the feature maps and hit them with a relu\n",
    "        inception2 = tf.nn.relu(tf.concat(3,[conv2_1x1_1,conv2_3x3,conv2_5x5,conv2_1x1_4]))\n",
    "\n",
    "        #flatten features for fully connected layer\n",
    "        inception2_flat = tf.reshape(inception2,[-1,28*28*4*map2])\n",
    "        \n",
    "        #Fully connected layers\n",
    "        if train:\n",
    "            h_fc1 =tf.nn.dropout(tf.nn.relu(tf.matmul(inception2_flat,W_fc1)+b_fc1),dropout)\n",
    "        else:\n",
    "            h_fc1 = tf.nn.relu(tf.matmul(inception2_flat,W_fc1)+b_fc1)\n",
    "\n",
    "        return tf.matmul(h_fc1,W_fc2)+b_fc2\n",
    "    \n",
    "    \n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(model(X),y_))\n",
    "    opt = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "    \n",
    "    predictions_val = tf.nn.softmax(model(tf_valX,train=False))\n",
    "    predictions_test = tf.nn.softmax(model(tf_testX,train=False))\n",
    "    \n",
    "    #initialize variable\n",
    "    init = tf.initialize_all_variables()\n",
    "    \n",
    "    #use to save variables so we can pick up later\n",
    "    saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n",
      "Model restored.\n",
      "step: 0\n",
      "validation accuracy: 98.6\n",
      " \n",
      "step: 100\n",
      "validation accuracy: 98.4\n",
      " \n",
      "step: 200\n",
      "validation accuracy: 98.4\n",
      " \n",
      "step: 300\n",
      "validation accuracy: 98.6\n",
      " \n",
      "step: 400\n",
      "validation accuracy: 98.4\n",
      " \n",
      "step: 500\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 600\n",
      "validation accuracy: 98.2\n",
      " \n",
      "step: 700\n",
      "validation accuracy: 98.0\n",
      " \n",
      "step: 800\n",
      "validation accuracy: 97.8\n",
      " \n",
      "step: 900\n",
      "validation accuracy: 98.2\n",
      " \n"
     ]
    }
   ],
   "source": [
    "num_steps = 20000\n",
    "sess = tf.Session(graph=graph)\n",
    "\n",
    "#initialize variables\n",
    "sess.run(init)\n",
    "print(\"Model initialized.\")\n",
    "\n",
    "#set use_previous=1 to use file_path model\n",
    "#set use_previous=0 to start model from scratch\n",
    "use_previous = 1\n",
    "\n",
    "#use the previous model or don't and initialize variables\n",
    "if use_previous:\n",
    "    saver.restore(sess,file_path)\n",
    "    print(\"Model restored.\")\n",
    "\n",
    "#training\n",
    "for s in range(num_steps):\n",
    "    offset = (s*batch_size) % (len(trainX)-batch_size)\n",
    "    batch_x,batch_y = trainX[offset:(offset+batch_size),:],train_lb[offset:(offset+batch_size),:]\n",
    "    feed_dict={X : batch_x, y_ : batch_y}\n",
    "    _,loss_value = sess.run([opt,loss],feed_dict=feed_dict)\n",
    "    if s%100 == 0:\n",
    "        feed_dict = {tf_valX : valX}\n",
    "        preds=sess.run(predictions_val,feed_dict=feed_dict)\n",
    "        \n",
    "        print \"step: \"+str(s)\n",
    "        print \"validation accuracy: \"+str(accuracy(val_lb,preds))\n",
    "        print \" \"\n",
    "        \n",
    "    #get test accuracy and save model\n",
    "    if s == (num_steps-1):\n",
    "        #create an array to store the outputs for the test\n",
    "        result = np.array([]).reshape(0,10)\n",
    "\n",
    "        #use the batches class\n",
    "        batch_testX=test_batchs(testX)\n",
    "\n",
    "        for i in range(len(testX)/test_batch_size):\n",
    "            feed_dict = {tf_testX : batch_testX.nextBatch(test_batch_size)}\n",
    "            preds=sess.run(predictions_test, feed_dict=feed_dict)\n",
    "            result=np.concatenate((result,preds),axis=0)\n",
    "        \n",
    "        print \"test accuracy: \"+str(accuracy(test_lb,result))\n",
    "        \n",
    "        save_path = saver.save(sess,file_path)\n",
    "        print(\"Model saved.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
